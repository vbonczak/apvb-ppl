\documentclass[svgnames]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage[a4paper,margin=1in]{geometry}

\usepackage{vincent} 
\usepackage{listings}

\usepackage{lmodern}

\lstset{
basicstyle=\ttfamily,
keywords = [1]{method, count},
keywords=[2]{let,dist, if, then, else, endif,for,to,do,done,begin,end},
keywords=[3]{sample, infer,observe, print, factor},
otherkeywords={% Operators
    |, ->, !,^
  },
sensitive=true,  
morecomment=[s]{(*}{*)}, 
keepspaces=true,
morestring=[b]",
keywordstyle=[2]\color{blue},
keywordstyle=[3]\color{DarkRed},
keywordstyle=\color{violet},
stringstyle=\color{DarkGreen},
tabsize=4,
showspaces=false,
breaklines=true
}
 

\begin{document}

\title{Un langage probabiliste basé sur Caml}

\author{Adam Phillips, Vincent Bonczak}

\date{MPRI 2021-2022}

\maketitle

\begin{abstract}
Ce document est le rapport sur le projet du cours de \emph{Langages de Programmation Probabilistes} (cours 2.40 du MPRI). 
Le projet permet d'appliquer les algorithmes d'inférence et les méthodes d'analyse des langages probabilistes rencontrés durant le cours. 
Notre développement s'est concentré sur l'implémentation d'un petit langage inspiré de Caml pour écrire des programmes, compilés ensuite vers
l'OCaml, disposant d'un environnement  d'exécution comportant plusieurs méthodes d'inférence.
\end{abstract}

\section{Travail réalisé}

Nous avons implémenté le projet sous la forme d'un compilateur d'un langage simple vers l'OCaml, compilé avec une bibliothèque de fonctions d'inférence.
Ce langage s'inspire de Caml pour les appels et les instructions de contrôle, en le simplifiant. Par exemple le programme suivant peut être utilisé pour compiler l'exemple \verb|funny_bernoulli| vu en cours :
\begin{lstlisting}
method Rejection

let funny_bernoulli  () =  
 let a = sample (bernoulli 0.5);
 let b = sample (bernoulli 0.5);  
 let c = sample (bernoulli 0.5); 
assume (a=1||b=1)
a+b+c
;

let _ = 
print ".-- Funny Bernoulli, Basic Rejection Sampling --."
dist d = infer funny_bernoulli;
print d
;
\end{lstlisting}

 
Plusieurs constructions probabilistes comme \verb|assume| ou \verb|infer| sont supportées, ainsi qu'une fonction d'affichage rapide de résultats \verb|print|.
On peut modifier le nombre d'échantillons dans plusieurs méthodes d'inférence à l'aide de la commande \lstinline|count << <n>|.
On change la méthode avec \lstinline|method <nom>|, parmi  \verb|Rejection|, \verb|Importance|, \verb|MetroSingle| et \verb|MetroMulti|.

Nous avons opté pour un langage à parser pour pouvoir faire du typage et de l'analyse statique (cependant par manque de temps nous n'avons implémenté que le typage simple, l'analyse statique s'étant révélée chronophage à développer).
Le typage vérifie que l'on échantillonne bien une distribution par exemple (soit une des valeurs existantes\footnote{Les distributions supportées sont \texttt{bernoulli normal uniform binomial bernoulli\_f uniform\_int}.} dans le langage comme \verb|bernoulli| ou une distribution issue d'une inférence, introduite par le mot-clé \lstinline{dist}).

La construction \lstinline{dist} est analogue au \lstinline{let}, et se termine par un point-virgule. En général et à part ces deux constructions, les instructions sont des lignes (à la différence du Caml qui peut avoir une application sur plusieurs lignes par exemple). 

La conditionnelle \lstinline{if then else endif} s'assortit de la limite de fin, ce qui permet de spécifier une structure avec une séquence d'instructions dans chaque cas, sans forcément passer par \lstinline{begin...end}.

Pour les autres structures de contrôle, nous avons mimé Caml (nous proposons par exemple la boucle \lstinline{for} qui est identique).

Pour finir, l'assignement se fait de la même manière pour les tableaux et pour les variables référence : via l'opérateur \verb|:=|, et le signe négatif (\verb|-| unaire) est le même pour les flottants et pour les entiers.



\section{Distributions}

Nous avons créé le type \verb|'a support| pour les distributions finies, et le type \texttt{'a dist} pour représenter les distributions. Le type \texttt{support} sontient donc un champ pour les valeurs, un champ pour les probabilités, et un champ pour les probabilités logarithmiques de chaque valeur. Le type \texttt{dist} contient alors un support optionnel, une fonction d'échantillonnage, une fonction pour obtenir la densité logarithmique d'une valeur, et une espérance et une variance optionnelles.

Nous avons aussi créé des distributions communes pouvant être appelées directement par l'utilisateur dans le code, telle que la distribution Bernoulli dépendant d'un paramètre \texttt p, et la distribution uniforme sur un segment des réels, dépendant de deux paramètres \texttt a et \texttt b.

\section{Rejection Sampling et Importance Sampling}

Pour la méthode par rejet, nous utilisons l'exception \texttt{Reject}, qui est interpellée lorsque le contenu d'une instruction \texttt{assume} se révèle fausse. Il suffit donc d'éxecuter la fonction \texttt{f} à inférer autant de fois que voulu, en relançant l'éxecution lorsque l'exception Reject est détectée.

Pour la méthode par rejet, les fonctions \texttt f données par l'utilisateur, et ensuite \texttt{factor}, \texttt{observe}, et \texttt{assume}, sont transformées pour aussi prendre en entrée une référence vers un flottant dénommée \texttt{score} (et non un tableau comme dans le cours). Ainsi, en donnant la valeur \texttt{0.} initialement à \texttt{score}, nous pouvons calculer le score de l'exécution, le mettant à \verb|neg_infinity| (probabilités logarithmiques) par exemple si nous avons une instruction \texttt{assume} dont l'argument est faux.

Pour ces deux méthodes, après avoir exécuté la fonction \texttt{f} autant de fois que nécessaire, nous combinons les valeurs identiques et additionnons leurs scores (qui vaut 1 pour chaque éxecution avec succès dans la méthode par rejet), et divisons par le score total pour obtenir la probabilité de chaque valeur.

\section{Metropolis-Hastings}

Nous avons implémenté deux versions de la méthode Metropolis-Hastings: l'inférence \emph{Multi-Sites} et l'inférence \emph{Single-Site}, qui sont appelées avec \lstinline{method MetroMulti}  et \lstinline{method MetroSingle} respectivement. Ces deux méthodes permettent de déterminer la distribution d'une fonction \verb|f| à l'aide d'une fonction de score \verb|score| pouvant évaluer les résultats de \verb|f|, et ainsi obtenir un score proportionnel à la distribution souhaitée.

Pour l'inférence \emph{Multi-sites}, nous avons procédé d'une manière similaire à l'inférence \emph{Importance Sampling}, avec après chaque éxecution de la fonction à inférer une analyse du score de l'évaluation actuelle de \verb|f| et du score de l'évaluation précédente. Le résultat à garder est donc déterminé avec ces scores et avec un flottant choisi aléatoirement entre \verb|0.| et \verb|1.|, comme indiqué dans le cours.

Pour l'inférence \emph{Single-site}, le but est de réexécuter seulement un des échantillonnages présents dans la fonction \verb|f| à chaque exécution, choisi de manière aléatoire et uniforme parmi tous les échantillonnages effectués dans \verb|f|. Si nous appelons \verb|x| ce rééchantillonnage, alors il est aussi nécessaire de refaire les échantillonnages dépendants de \texttt x, et de faire les échantillonnages non rencontrés lors de l'exécution précédente (par exemple le résultat de \texttt x pourrait nous faire changer de branche dans une instruction \verb|if|).

Pour ce faire, si l'utilisateur veut utiliser la méthode \emph{Metropolis-Hastings Single-site}, les fonctions écrites dans le programme en entrée vont être transformées pour aussi renvoyer la liste des variables échantillonnées lors de l'exécution, avec leur position précise dans le programme, les échantillonnages dépendants de cet échantillonnage, et la valeur ainsi échantillonnée. Ainsi, les variables ne sont pas uniquement déterminées par leur nom: il nous faut aussi la trace d'exécution du code pour connaître sa position précise. Il serait donc possible d'associer à une variable \verb|x| un échantillonnage à chaque itération d'une boucle \verb|for|, ou plusieurs fois d'affilée, et nous saurions quelle variable est laquelle et en choisir qu'une seule à rééchantillonner. Malheureusement, nous n'avons pas eu le temps de perfectionner ce système: les échantillonnages dans les boucles \verb|for| ne fonctionnent pas et associer un nouveau échantillonnage à une même variable n'est pas possible. Lors de l'exécution de la fonction, chaque variable ne peut être échantillonnée qu'une seule fois.

Néanmoins, lors de l'inférence, à chaque exécution nous pouvons utiliser la liste de sortie pour choisir un des échantillonnages aléatoirement pour pouvoir le rééchantillonner, ainsi que ses dépendances, lors de la prochaine exécution. Nous gardons la liste des variables connues en variable globale, et après avoir choisi la variable \verb|x| à rééchantillonner, nous enlevons \verb|x| et les échantillonnages dépendant de x de cette liste. Ainsi, la fonction \verb|sample| est modifiée pour d'abord regarder si la variable en question est présente dans la liste, et si elle l'est, elle utilise la valeur indiquée dans la liste, sinon elle échantillonne avec la fonction \verb|sample| associée à la distribution donnée. Cette liste est donc vide initialement, pour que toutes les variables soient échantillonnées lors de la première exécution.
  

%\section{La simulation}

 

\section{Conclusion}
 

Nous avons tenu à faire un langage différent de Caml (et plus simple, à l'image de WebPPL) mais cela nous a pris plus de temps que prévu. En effet, pour avoir une analyse lexico-syntaxique satisfaisante vis-à-vis de nos contraintes sur le langage, nous avons dû nous replonger dans ce domaine, et adapter quelque peu nos connaissances sur  \verb|(ocaml)yacc| pour créer quelque chose d'optimal avec \verb|menhir|.

L'aspect probabiliste a permis de revoir le cours et de repréciser certaines notions, comme l'inférence \emph{SingleSite} de Metropolis-Hastings -- nous avions compris le principe, mais le fait de l'implémenter a fixé les esprits.

\bigskip

Ensuite, une des choses intéressantes serait de réaliser un analyseur statique sur un code MLPPL donné, pour vérifier quelle plage de valeurs prennent les variables, et définir ainsi le bon fonctionnement du programme obtenu.

Sur un aspect plus pratique, le code prend en charge l'ajout de dépendances (des bibliothèques externes) à la compilation, mais pas le langage pour l'instant. Pour ajouter de la flexibilité on peut imaginer introduire une instruction dans l'esprit du "Open" de caml ou du "From Import" de python, en ajoutant chaque dépendance demandée lors de la compilation.

\end{document}